---
title: "Data Cleaning"
author: "Elia Zanini"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)

library(dplyr)
library(ggplot2)
library(plotly)
library(factoextra)
library(cluster)

```

#Importo il dataset, faccio una prima pulizia e tengo i dati dagli anni 2000, degli omicidi risolti

```{r}

dataset_path <- "D:/DESKTOP/Desktop/statistical learning pr/unsupervised 2/database.csv"
df <- read.csv(dataset_path)

#elimino colonne inutili
df$Record.ID <- NULL
df$Agency.Code <- NULL
df$Agency.Name <- NULL
df$Agency.Type <- NULL
df$City <- NULL
df$Victim.Ethnicity<- NULL
df$Perpetrator.Ethnicity<- NULL
df$Victim.Count<- NULL
df$Perpetrator.Count<- NULL
df$Record.Source<- NULL
df$Incident<- NULL
df$State <- NULL


df <- na.omit(df) #elimino righe con null values (df molto grande)
df <- df[!apply(df, 1, function(row) any(grepl("Unknown", row, ignore.case = TRUE))), ]
df <- df[df$Victim.Age <= 99 & df$Perpetrator.Age <= 99, ] #alcune età sono numeri inverosimili, limito a 99 anni

df <- df %>% filter(Perpetrator.Age >= 10) #tolgo casi con assassino <10 anni (involontari o falsi)

```


```{r}
df <- df %>%
  filter(Year >= 1990)

df <- df %>%
  filter(Crime.Solved == "Yes")

df$Crime.Solved <- NULL
df$Month <- NULL
df$Year <- NULL
```

verifico e salvo

```{r}

str(df)

output_path <- "D:/DESKTOP/Desktop/statistical learning pr/unsupervised 2/dfsolved.csv"
write.csv(df, output_path, row.names = FALSE)

```

#EXPLORATORY DATA A
##studio qualche dato interessante per comprendere il dataset, partendo dalla distribuzione delle età killer/vittime
```{r}
par(mfrow = c(1, 2))

#Victim age
qqnorm(df$Victim.Age, main = "QQ Plot - Victim Age", col = "steelblue")
qqline(df$Victim.Age, col = "red")

#perpetrator age
qqnorm(df$Perpetrator.Age, main = "QQ Plot - Perpetrator Age", col = "darkgreen")
qqline(df$Perpetrator.Age, col = "red")

par(mfrow = c(1, 1)) #resetto

```

##creo nuova colonna che mostra rapporto tra vittima e killer, per vedere distribuzioni omicidi su sesso
```{r}
df$Combinazione <- paste(df$Perpetrator.Sex, "/", df$Victim.Sex)


tabella_sex <- df %>%
  count(Combinazione) %>%
  arrange(desc(n)) %>%
  mutate(Percentuale = round(n / sum(n) * 100, 1))

colnames(tabella_sex)[1] <- "Perpetrator / Victim SEX"
colnames(tabella_sex)[2] <- "n tot"
colnames(tabella_sex)[3] <- "% of total" 
tabella_sex



ggplot(tabella_sex, aes(x = "", y = `% of total`, fill = `Perpetrator / Victim SEX`)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  theme_void() +
  labs(title ="Distribution of kills by sex", fill ="Combination") +
  geom_text(aes(label =paste0(`% of total`, "%")),
            position = position_stack(vjust= 0.5),
            color = "white", size =4)

df$Combinazione<-NULL
```


```{r}

#qua creo una funzione per raggruppare le principali relazioni tra killer e vittima

classifica_relazione <- function(x) {
  x <- tolower(x)
  if (x %in% c("husband", "wife", "ex-husband", "ex-wife", "boyfriend", "girlfriend", "boyfriend/girlfriend", "common-law husband", "common-law wife")) {return("Partner/Ex Partner")} 
  
  else if (x %in% c("family", "father", "mother", "daughter", "son", "sister", "brother", "stepfather", "stepmother", "stepdaughter", "stepson", "in-law")) {return("Family")} 
  
  else if (x == "friend") {return("Friend")} 
  else if (x == "acquaintance") { return("Acquaintance")} 
  else if (x == "stranger") {return("Stranger")} 
  else {return("Other")}}


df$Relazione_Semplificata <- sapply(df$Relationship, classifica_relazione) #applico sul df

#sno interessato a trovare la statistica diversa per maschi e femmine dunque divido i dati per sesso
maschi <- df[df$Perpetrator.Sex == "Male", ]
femmine <- df[df$Perpetrator.Sex == "Female", ]



#funzione per creare tabella e tenere solo le prime 5 categorie
pie_data <- function(dati) {
  tab <-  as.data.frame(table(dati$Relazione_Semplificata))
  colnames(tab)<- c("Relazione", "Frequenza")
  tab <-tab[order(-tab$Frequenza), ]
  tab <- head(tab, 5)
  tab$Percentuale <-  round(tab$Frequenza /sum(tab$Frequenza)* 100, 1)
  return(tab)}

rel_maschi <- pie_data(maschi)
rel_femmine <- pie_data(femmine)

#torta maschi
ggplot(rel_maschi, aes(x = "", y = Percentuale, fill = Relazione)) +
  geom_col(width = 1, color = "white") +
  coord_polar("y") +
  theme_void() +
  labs(title = "Male- relationship with victim (top 5)") +
  geom_text(aes(label = paste0(Percentuale, "%")),
            position = position_stack(vjust = 0.5), color = "white", size = 4)

#torta femmine
ggplot(rel_femmine, aes(x = "", y = Percentuale, fill = Relazione)) +
  geom_col(width = 1, color = "white") +
  coord_polar("y") +
  theme_void() +
  labs(title = "Female - Relationship with victim (top 5)") +
  geom_text(aes(label = paste0(Percentuale, "%")),
            position = position_stack(vjust = 0.5), color = "white", size = 4)

df$Relazione_Semplificata<-NULL
```


#VARIABLES TRASFORMATIONS
inizio a trasformare le variabili categoriche in numeriche per PCA e clustering


##parto dalle piu semplici (dummy)
```{r}

#volontario =1, non volontario =0
df$Crime.Type <-ifelse(grepl("Murder", df$Crime.Type), 1, 0)

#Victim.Sex (0 = male, 1 = fem)
df$Victim.Sex <-ifelse(df$Victim.Sex == "Female", 1, 0)

#Perpetrator.Sex (0 = maschio, 1 = femm)
df$Perpetrator.Sex <-ifelse(df$Perpetrator.Sex== "Female", 1, 0)

#Weapon (Arma da fuoco = 1, resto = 0)
df$Weapon <-ifelse(grepl("Handgun|Shotgun|Rifle|Firearm", df$Weapon),1, 0)

```
##variabile Relationship 
divido i casi di omicidi tra relazioni con la vittima "strette" (0) e non (1)
```{r}
table(df$Relationship)

contatti_non_stretti <- c("Stranger", "Acquaintance", "Employee", "Employer")

#Dummy: 1 = NON contatto stretto, 0 = contatto stretto
df$Rel_NotClose <- ifelse(df$Relationship %in% contatti_non_stretti, 1, 0)

table(df$Rel_NotClose)
df$Relationship<-NULL

```
##variabile "race"
semplifico le due colonne di variabili in un unica dummy
casi in cui killer e vittima hanno la stessa etnia (1), e casi in cui è diversa(0)
```{r}
df$Victim.Race <- tolower(df$Victim.Race)
df$Perpetrator.Race <-tolower(df$Perpetrator.Race)

df$Same_Race<- ifelse(df$Victim.Race == df$Perpetrator.Race, 1, 0)

df$Victim.Race <- NULL
df$Perpetrator.Race <- NULL

```

##check finale
```{r} 
str(df)
```


#PCA
```{r}
df_scaled <-scale(df) #scalo tutte le variabili standardizzandole

pca_result<- prcomp(df_scaled, center = TRUE, scale. = TRUE)

#Scree plot: percentuale di varianza spiegata da ciascun componente
pca_var <- pca_result$sdev^2
pca_var_perc <-round(pca_var / sum(pca_var) * 100, 1) 

barplot(pca_var_perc,
        main = "Scree Plot - PCA",
        xlab ="Principal Component",
        ylab = "Percentuale di varianza spiegata",
        names.arg = paste0("PC", 1:length(pca_var_perc)),
        col = "lightblue")



#creo dataset con le principal components
pca_df <-as.data.frame(pca_result$x)
pca_df$Cluster <- NA  # inizialmente nessun cluster assegnato

#loadings sono le direzioni delle variabili originali
loadings<- as.data.frame(pca_result$rotation[, 1:2])
loadings$Variable <- rownames(loadings)

#Visualizzazione PCA con frecce
library(ggplot2)
library(grid)  # per freccia

ggplot(pca_df, aes(x =PC1, y= PC2)) +
  geom_point(alpha = 0.4, color = "steelblue") +
  geom_segment(data=loadings, aes(x = 0, y = 0, xend = PC1* 5, yend=PC2 * 5), arrow = arrow(length=unit(0.2, "cm")), color= "darkred", size = 0.8) +
  geom_text(data = loadings,
            aes(x =PC1 * 5.5, y =PC2 * 5.5, label = Variable),
            color ="darkred", size= 4) +
  theme_minimal() +
  labs(title = "Biplot PCA con frecce (loadings)",
       x = paste0("PC1 (",pca_var_perc[1],"%)"),
       y = paste0("PC2 (", pca_var_perc[2], "%)"))
```



```{r}
round(pca_result$rotation[,1:2], 2)
```


#ELBOW PLOT 
per capire quanti n clusters usare
```{r}
wss <- numeric(10)

for (k in 1:10) {
  kmeans_result<- kmeans(pca_df[, 1:2], centers= k, nstart = 25)
  wss[k] <-kmeans_result$tot.withinss
}

plot(1:10, wss, type = "b", pch = 19,
     xlab = "n cluster",
     ylab = "WSS",
     main = "Elbow Plot")

```
#KMEANS
3 clusters
```{r}

set.seed(123)

#tengo 3 kluster secondo elbow plot.. applico
kmeans_result <- kmeans(pca_df[, 1:2], centers = 3, nstart = 25, iter.max = 100)
pca_df$Cluster <- as.factor(kmeans_result$cluster)

#attenzione: metto i cluster in formato numerico (serve dopo per silhouette)
cluster_kmeans <- as.numeric(pca_df$Cluster)

#grafico 2D
library(ggplot2)

ggplot(pca_df, aes(x = PC1, y= PC2, color = Cluster)) +
  geom_point(alpha = 0.6) +
  theme_minimal() +
  labs(title = "Cluster K-means (k = 3) sulla PCA",
       x = paste0("PC1(", pca_var_perc[1], "%)"),
       y =paste0("PC2 (", pca_var_perc[2],"%)"),
       color ="Cluster")

```

##3D plot per aiutarci nella comprensione e divisione visiva
```{r}


#grafico imn 3D con plotly
plot_ly(pca_df, x = ~PC1, y = ~PC2,z = ~PC3,
        color = ~Cluster, colors = c("tomato", "steelblue", "darkgreen"),
        type ="scatter3d", mode = "markers",marker=list(size=1)) %>%
  layout(title = "K-means clustering in 3D (PC1-PC2-PC3)",
         scene = list(
           xaxis = list(title = paste0("PC1 (", pca_var_perc[1], "%)")),
           yaxis = list(title = paste0("PC2 (", pca_var_perc[2], "%)")),
           zaxis = list(title = paste0("PC3 (", pca_var_perc[3], "%)"))
         ))
#noto un gruppetto di outliers.. provvedo dopo ad indagare a che variabili sono dovuti

```

##analizzo le caratteristiche medie per ogni cluster! per comprendere le differenze effettive
```{r}

#unisco i cluster al dataframe originale
df_clustered <- cbind(df, Cluster = pca_df$Cluster)

# Calcolo statistiche medie per ogni cluster.. ANALISI INDISPENSABILE per capire le caratteristiche principali di 3 tipi di omicidio!!
df_clustered %>%
  group_by(Cluster) %>%
  summarise(
    Count = n(),
    Età_media_vittima = round(mean(Victim.Age), 1),
    Età_media_colpevole = round(mean(Perpetrator.Age), 1),
    Percent_donne_vittime = round(mean(Victim.Sex == 1) * 100, 1),
    Percent_donne_colpevoli = round(mean(Perpetrator.Sex == 1) * 100, 1),
    Percent_arma_fuoco = round(mean(Weapon == 1) * 100, 1),
    Percent_rel_non_stretta = round(mean(Rel_NotClose == 1) * 100, 1),
    Percent_same_race = round(mean(Same_Race == 1) * 100, 1)
  )


```
##Silhouette analisi
```{r}
set.seed(123)
sample_idx <- sample(nrow(pca_df), 10000)
pca_small <- pca_df[sample_idx, 1:2]
cluster_small <- as.numeric(pca_df$Cluster[sample_idx])

#istanza e silhouette
dist_small <- dist(pca_small)
sil <- silhouette(cluster_small, dist_small)


fviz_silhouette(sil) #grafico

```

##extra: provo a fare una cosa interessante
individo gli outlier rispetto ai cluster trovati, ovvero i punti con silhouette negativa.
Questo per comprendere la parte di dati che si distribuisce più distante dai centroidi, non adattandosi bene ai klusters

```{r}
#subset usato per la silhouette
set.seed(123)
sample_idx <- sample(nrow(pca_df), 10000)
pca_small <- pca_df[sample_idx, 1:2]
cluster_small <- as.numeric(pca_df$Cluster[sample_idx])


sil_df <- as.data.frame(sil) #lo trasformo in df

#ATTENZIONE.. prendo solo le distanze negative, per risalire alle variabili iniziali che danno "problemi"
outliers <- sil_df %>% filter(sil_width < 0)

#recupero i dati originali collegati a tali valori
outlier_idx <- as.integer(rownames(outliers))
dati_outlier <- df_clustered[sample_idx[outlier_idx], ]

dati_outlier

```

#CLUSTERING GERARCHICO
tecnica alternativa al k-means
```{r}

set.seed(123)
sample_idx <- sample(nrow(pca_df), 10000)  #subset per alleggerire i calcoli

pca_subset<- pca_df[sample_idx, 1:2]  #uso solo i primi due componenti

#calcolo distanzA euclidea tra i punti
dist_hc <-dist(pca_subset)

hc<- hclust(dist_hc, method = "ward.D2") #algoritmo gerarchico ward.D2 = cerca di minimizzare varianza interna

plot(hc, labels= FALSE, hang =-1, main = "Dendrogramma - Hierarchical Clustering")


#evidenzio a mano i cluster (k=3 come prima) e assegno i cluster trovati
rect.hclust(hc, k = 3, border= 2:4)
hc_clusters<- cutree(hc, k = 3)

```

#confronto finale
```{r}

#cluster da k-means sullo stesso sample usato per l'hierarchical
kmeans_sample <-as.numeric(pca_df$Cluster[sample_idx])

#tabella confronto
table(kmeans_sample, hc_clusters)

```









